{
    "AKG: automatic kernel generation for neural processing units using polyhedral transformations": {
        "date": "2022",
        "sharer": "Yi"
    },
    "DAPPLE: A Pipelined Data Parallel Approach for Training Large Models": {
        "date": "2022"
    },
    "GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism": {
        "date": "2022"
    },
    "TensorOpt: Exploring the Tradeoffs in Distributed DNN Training with Auto-Parallelism": {
        "date": "2022",
        "sharer": "Xu"
    },
    "Exploring Hidden Dimensions in Parallelizing Convolutional Neural Networks": {
        "date": "2021",
        "sharer": "Yi"
    },
    "Beyond Data and Model Parallelism for Deep Neural Networks": {
        "date": "2021",
        "sharer": "Ni"
    },
    "One weird trick for parallelizing convolutional neural networks": {
        "date": "2021",
        "sharer": "Ni"
    },
    "Alpa: Automating Inter- and Intra-Operator Parallelism for Distributed Deep Learning": {
        "date": "2022",
        "sharer": "Wang Wei"
    }
}